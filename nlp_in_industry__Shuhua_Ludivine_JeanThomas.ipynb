{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10014608,
          "sourceType": "datasetVersion",
          "datasetId": 6165684
        },
        {
          "sourceId": 10016729,
          "sourceType": "datasetVersion",
          "datasetId": 6167333
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview(problematics&highlights)\n",
        "\n",
        "# Our problematics:\n",
        "Through carefuly analysis of the baseline solution and our own experimentations, we've been targetting at tackling:\n",
        "\n",
        "-**Date missing** in the extracted text due to inadequate OCR or leaving out pages(e.g. date information in irregular font or image format, and dates appearing at the end of the document)\n",
        "\n",
        "-**Lack of a benchmark dataset** and a set of consistent annotation rules with high-quality human annotation on which to test and improve the predictor.\n",
        "\n",
        "-**Economize the computation** of LLM's inference by giving as the input only most relevant informations\n",
        "\n",
        "-**Fully utilize the LLM's knowledge** to make a good judgement among several possible dates and even correct some OCR errors\n",
        "\n",
        "Responding to the above problematics, we present:\n",
        "\n",
        "\n",
        "# Highlights of the work:\n",
        "\n",
        "*  **Better quality OCR**(we used the best-performing open-source OCR model we found: **PaddleOCR** by Baidu China), especially effective for keeping and recognizing the dates of irregular font/format\n",
        "\n",
        "*  **A benchmark dataset** strictly **annotated by our native French** members following a set of **reasonable and consistent annotation rules**(see evaluation part), including the most challenging examples\n",
        "\n",
        "*  **Economize the computation of LLM** while keeping good performance with a highly efficient input: **NER Dates with their contexutal characters** of the doc's **first pages and final pages**\n",
        "\n",
        "*  Utilize the **prompting(few-shot learning and simple CoT)** to refine LLM(Qwen)'s inference and further **compensente inevitable OCR flaws**\n",
        "\n",
        "\n",
        "Result: compared with the Datapolitcs baseline, **our predictor shows obvious performance improvement(more than 10% on our challenge benchmark dataset** and more than 5% on the class's collaborative annotation dataset, see the Evaluation part)\n",
        "\n"
      ],
      "metadata": {
        "id": "LWLUgXz6UTKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This pipeline conerns:\n",
        "\n",
        "1. PDF and original Data preparation\n",
        "\n",
        "2. OCR: PDF(to image)to Text\n",
        "\n",
        "3. NER dates extraction with contextual information\n",
        "\n",
        "4. LLM(Qwen 2.5)-based predictor(prompted)\n",
        "\n",
        "5. Evaluation"
      ],
      "metadata": {
        "id": "SI6yf4uFWuYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF and original Data preparation\n"
      ],
      "metadata": {
        "id": "-etjO3coXOLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!pip install pymupdf pytesseract pdfplumber\n",
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "import pdfplumber\n",
        "import requests\n",
        "!pip install datasets\n",
        "from datasets import load_dataset,Dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForTokenClassification, pipeline\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "ZPenjK6Z22kR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-30T16:58:42.663396Z",
          "iopub.execute_input": "2024-11-30T16:58:42.663755Z",
          "iopub.status.idle": "2024-11-30T16:59:26.733181Z",
          "shell.execute_reply.started": "2024-11-30T16:58:42.663725Z",
          "shell.execute_reply": "2024-11-30T16:59:26.732337Z"
        },
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956081d1-8690-4148-ef53-754c942c841d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytesseract, pypdfium2, pymupdf, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pymupdf-1.24.14 pypdfium2-4.30.0 pytesseract-0.3.13\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the url/cache and doc_id from the original dataset provided by the teacher\n",
        "import pandas as pd\n",
        "\n",
        "original_data_df = pd.read_csv(\"/content/dataset (2).csv\")\n",
        "\n",
        "new_data_df = original_data_df[['doc_id', 'url', 'cache']]\n"
      ],
      "metadata": {
        "id": "btmWj7sgN07Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to download the pdf from the URL\n",
        "def download_and_save_pdf(cache_url, url, filename):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    # try cache first\n",
        "    try:\n",
        "        response = requests.get(cache_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        with open(f\"{filename}.pdf\", \"wb\") as file: # make name of file its row in the df\n",
        "            file.write(response.content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error cache url: {e}\") # get row id in google sheet file where there is a problem\n",
        "        print(\"trying other url ...\")\n",
        "\n",
        "        # if it doesn't work try url\n",
        "        try:\n",
        "          response = requests.get(url, headers=headers)\n",
        "          response.raise_for_status()\n",
        "\n",
        "          with open(f\"{filename}.pdf\", \"wb\") as file: # make name of file its row in the df\n",
        "              file.write(response.content)\n",
        "\n",
        "        except Exception as e2:\n",
        "           print(f\"Error normal url: {e2}\") # get row id in google sheet file where there is a problem\n",
        "           print(\"No urls work\")"
      ],
      "metadata": {
        "id": "WZVb-PLCz2os",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-30T16:59:40.564345Z",
          "iopub.execute_input": "2024-11-30T16:59:40.565240Z",
          "iopub.status.idle": "2024-11-30T16:59:40.572379Z",
          "shell.execute_reply.started": "2024-11-30T16:59:40.565192Z",
          "shell.execute_reply": "2024-11-30T16:59:40.571226Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OCR: PDF to Text\n"
      ],
      "metadata": {
        "id": "60JbDFIAeLef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddlepaddle-gpu==2.5.2 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
        "!pip install paddleocr\n",
        "from paddleocr import PaddleOCR, draw_ocr\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize the OCR model\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang=\"fr\",show_log=False)  # 使用中文模型\n",
        "\n",
        "\n",
        "def text_from_pdf(pdf_path):\n",
        "    pdf_doc = fitz.open(pdf_path)\n",
        "    num_pages = len(pdf_doc)\n",
        "\n",
        "    extracted_content = []  # list[str]\n",
        "    # define a range of targed pages\n",
        "    pages2consider = [page_id for page_id in [0,1,2,-2,-1] if -num_pages <= page_id < num_pages]\n",
        "\n",
        "    for page_idx in pages2consider:\n",
        "        page = pdf_doc[page_idx]\n",
        "\n",
        "        #PaddleOCR only accepts image: convert PDF to image\n",
        "        pix = page.get_pixmap(dpi=300)\n",
        "        image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "        image_np = np.array(image)\n",
        "\n",
        "        #OCR-processing\n",
        "        ocr_text = ocr.ocr(image_np, cls=True)\n",
        "        if ocr_text[0] != None:\n",
        "            texts = [res[1][0] for res in ocr_text[0]]  # convert to texts\n",
        "            extracted_content.extend(texts)\n",
        "\n",
        "    return extracted_content\n"
      ],
      "metadata": {
        "id": "CMJr_6ro7lY3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-30T16:59:40.573583Z",
          "iopub.execute_input": "2024-11-30T16:59:40.573908Z",
          "iopub.status.idle": "2024-11-30T16:59:40.589370Z",
          "shell.execute_reply.started": "2024-11-30T16:59:40.573880Z",
          "shell.execute_reply": "2024-11-30T16:59:40.588313Z"
        },
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a650cc85-a1fe-426c-ea29-e0c655baa7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
            "Collecting paddlepaddle-gpu==2.5.2\n",
            "  Downloading paddlepaddle_gpu-2.5.2-cp310-cp310-manylinux1_x86_64.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.5.2) (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.5.2) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.5.2) (11.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.5.2) (4.4.2)\n",
            "Collecting astor (from paddlepaddle-gpu==2.5.2)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting opt-einsum==3.3.0 (from paddlepaddle-gpu==2.5.2)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu==2.5.2) (4.25.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu==2.5.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->paddlepaddle-gpu==2.5.2) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle-gpu==2.5.2) (1.2.2)\n",
            "Downloading paddlepaddle_gpu-2.5.2-cp310-cp310-manylinux1_x86_64.whl (542.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.5/542.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Installing collected packages: opt-einsum, astor, paddlepaddle-gpu\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "Successfully installed astor-0.8.1 opt-einsum-3.3.0 paddlepaddle-gpu-2.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "opt_einsum"
                ]
              },
              "id": "4c1cf8a9fe3d4582a1de0c0bfd1ff58f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddleocr\n",
            "  Downloading paddleocr-2.9.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from paddleocr) (2.0.6)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.24.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.4.0)\n",
            "Collecting pyclipper (from paddleocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting lmdb (from paddleocr)\n",
            "  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.66.6)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.26.4)\n",
            "Collecting rapidfuzz (from paddleocr)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.10.0.84)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.10.0.84)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from paddleocr) (3.0.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddleocr) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from paddleocr) (6.0.2)\n",
            "Collecting python-docx (from paddleocr)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.12.3)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.55.0)\n",
            "Collecting fire>=0.3.0 (from paddleocr)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from paddleocr) (2.32.3)\n",
            "Collecting albumentations==1.4.10 (from paddleocr)\n",
            "  Downloading albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting albucore==0.0.13 (from paddleocr)\n",
            "  Downloading albucore-0.0.13-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.13->paddleocr) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.13->paddleocr) (4.12.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.13->paddleocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->paddleocr) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->paddleocr) (1.5.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->paddleocr) (2.9.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->paddleocr) (2.5.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->paddleocr) (2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr) (3.8.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->paddleocr) (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (2024.8.30)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (2.23.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (2.8.2)\n",
            "Downloading paddleocr-2.9.1-py3-none-any.whl (544 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.7/544.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.13-py3-none-any.whl (8.5 kB)\n",
            "Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=18292f58b2c14d1cb59f3d1aaa01dae0017f4112d4a0fadf7f9792623a7c7614\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: pyclipper, lmdb, rapidfuzz, python-docx, fire, albucore, albumentations, paddleocr\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.19\n",
            "    Uninstalling albucore-0.0.19:\n",
            "      Successfully uninstalled albucore-0.0.19\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed albucore-0.0.13 albumentations-1.4.10 fire-0.7.0 lmdb-1.5.1 paddleocr-2.9.1 pyclipper-1.3.0.post6 python-docx-1.1.2 rapidfuzz-3.10.1\n",
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3910/3910 [00:15<00:00, 248.03it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/latin_PP-OCRv3_rec_infer.tar to /root/.paddleocr/whl/rec/latin/latin_PP-OCRv3_rec_infer/latin_PP-OCRv3_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9930/9930 [00:17<00:00, 554.86it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2138/2138 [00:15<00:00, 141.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024/12/01 20:07:41] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024/12/01 20:07:42] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
            "[2024/12/01 20:07:43] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#The mapping function\n",
        "def pdf_to_text_paddleOCR(row):\n",
        "  download_and_save_pdf(row[\"cache\"], row[\"url\"], row.name)\n",
        "\n",
        "  if os.path.exists(f\"{row.name}.pdf\"):\n",
        "    text = text_from_pdf(f\"{row.name}.pdf\")\n",
        "    row[\"text\"] = text\n",
        "    os.remove(f\"{row.name}.pdf\") # save memory\n",
        "  print(row.name)\n",
        "  return row"
      ],
      "metadata": {
        "id": "8BVR_KyZPFux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply the pdf_to_text_paddleOCR mapping for examples(previous 200 rows)\n",
        "new_data_df[\"text\"] = None\n",
        "new_data_df.loc[:199] = new_data_df.loc[:199].apply(pdf_to_text_paddleOCR, axis=1)\n",
        "\n",
        "#Saving for safe\n",
        "new_data_df_2 = new_data_df.copy()\n",
        "\n",
        "new_data_df_2.to_pickle(\"new_data_df_text_200.pkl\")"
      ],
      "metadata": {
        "id": "uqZD8rwdT0C9",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf4d4e0c-704f-4752-9f10-50834f68dac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "Error cache url: 403 Client Error: Forbidden for url: https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/2785/384c7_D%C3%A9lib%C3%A9rations_Conseil_Communautaire_27_f%C3%A9vrier_2023.pdf\n",
            "trying other url ...\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "Error cache url: 403 Client Error: Forbidden for url: https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/2512/b2cf4_CR_09_f%C3%A9vrier_2023.pdf\n",
            "trying other url ...\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "Error cache url: 403 Client Error: Forbidden for url: https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/2965/18c3595af8e450d0b8afffe9827a617fcfa8450f_Rapport%20de%20P\n",
            "trying other url ...\n",
            "49\n",
            "50\n",
            "Error cache url: 403 Client Error: Forbidden for url: https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/1970/5011763f908fe9bdec498bdf9cb1517bb66fbb56_PV%20CC%20du%203\n",
            "trying other url ...\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "Error cache url: 403 Client Error: Forbidden for url: https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/1342/99118_PV%20int%C3%A9gral%20CM%20121222.pdf\n",
            "trying other url ...\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "Error cache url: 403 Client Error: Forbidden for url: https://datapolitics-public.s3.gra.io.cloud.ovh.net/LORIA/3029/a18582e994fceea2089730c835eba47315a1cc6d_d%C3%A9lib%C3%A9\n",
            "trying other url ...\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ac52e08339fb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Apply the pdf_to_text_paddleOCR mapping for examples(previous 200 rows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m199\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m199\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_to_text_paddleOCR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Saving for safe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-698d01a6a106>\u001b[0m in \u001b[0;36mpdf_to_text_paddleOCR\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#The mapping function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpdf_to_text_paddleOCR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdownload_and_save_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{row.name}.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cca7d70b6ae0>\u001b[0m in \u001b[0;36mdownload_and_save_pdf\u001b[0;34m(cache_url, url, filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# try cache first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLSocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mtls_in_tls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             sock = connection.create_connection(\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mLocationParseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{host}', label empty or too long\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;31m# and socket type values to enum constants.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         addrlist.append((_intenum_converter(af, AddressFamily),\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dates NER with contexutal information"
      ],
      "metadata": {
        "id": "Ly8lWw5jkWYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Intitialize a good-performing French NER model 'camembert-ner-with-dates' (thanks to the recommendation of our classmate Xu Sun)\n",
        "ner_tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")\n",
        "ner_pipe = pipeline('ner', model=ner_model, tokenizer=ner_tokenizer, aggregation_strategy=\"simple\",device=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-30T16:59:40.590767Z",
          "iopub.execute_input": "2024-11-30T16:59:40.591138Z",
          "iopub.status.idle": "2024-11-30T16:59:43.974992Z",
          "shell.execute_reply.started": "2024-11-30T16:59:40.591088Z",
          "shell.execute_reply": "2024-11-30T16:59:43.974060Z"
        },
        "id": "eZDzkWNqkWYw",
        "collapsed": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to extract dates and the contextual informations\n",
        "def get_original_text_for_dates(texts,window_size=1):\n",
        "    results=[]\n",
        "    if not texts :\n",
        "        return []\n",
        "\n",
        "    else:\n",
        "        for idx in range(len(texts)):\n",
        "            text = texts[idx]\n",
        "            ner_results = ner_pipe(text)\n",
        "            for ner_dict in ner_results:\n",
        "                if ner_dict[\"entity_group\"] == \"DATE\":\n",
        "                    if idx > 0:\n",
        "                        results.extend([texts[idx-1], text]) #in case the pre-context is seperated from the date itself\n",
        "                    else: #idx == 0\n",
        "                        results.append(text)\n",
        "\n",
        "    return results\n",
        "\n",
        "def text_to_NER_Date_map(row):\n",
        "    Dates = get_original_text_for_dates(row['text'])\n",
        "    row[\"Date_NER\"] = Dates\n",
        "    print(row.name)\n",
        "    return row"
      ],
      "metadata": {
        "id": "_fFwcC6l3L_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply text_to_NER_Date_map to examples(the first 200 rows)\n",
        "new_data_df['Date_NER'] = None\n",
        "new_data_df.loc[:199] = new_data_df.loc[:199].apply(text_to_NER_Date_map, axis=1)\n",
        "new_data_df.to_pickle(\"new_data_df_NER_200.pkl\")#save for safe"
      ],
      "metadata": {
        "id": "IPEDu4cMdeJr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM-based predictor"
      ],
      "metadata": {
        "id": "GdFyoCzseP1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "7cJ7CKKooInY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-30T17:00:02.663100Z",
          "iopub.execute_input": "2024-11-30T17:00:02.664097Z",
          "iopub.status.idle": "2024-11-30T17:06:57.476163Z",
          "shell.execute_reply.started": "2024-11-30T17:00:02.664053Z",
          "shell.execute_reply": "2024-11-30T17:06:57.475149Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse\n",
        "def get_llm_date_prediction(text,url):\n",
        "  prompt = f\"\"\"\n",
        "  Voici des informations extraites d'un document administratif :\n",
        "  {text}\n",
        "\n",
        "  Question : Quelle est la date de publication de ce document ?\n",
        "\n",
        "  Répondez uniquement par la date de publication au format JJ/MM/AAAA (jour/mois/année).\n",
        "  Si aucune date correcte n'est pas mentionnée dans le texte, essayez de l'extraire à partir de l'URL suivante : {urllib.parse.unquote(url)}.\n",
        "  Si la date semble incorrecte, corrigez-la utilisant tes connaissances et donnez uniquement la date corrigée sous la forme JJ/MM/AAAA.\n",
        "  Exemple：Dans '37/02/2023', 37 est invalide pour le mois 02, corrigez-la et donnez donc 27/02/2023.\n",
        "  Exemple: Dans'3 0 MAl 2023'corrigez-la et donnez donc '30/05/2023'\n",
        "\n",
        "\n",
        "\n",
        "  Ne donnez aucune autre information ou texte en dehors de la date sous la forme JJ/MM/AAAA\n",
        "  Réponse :\n",
        "  \"\"\"\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Tu es un humain identifieur de la date de publication du texte\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        "\n",
        "  text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        "  )\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "  generated_ids = model.generate(\n",
        "      **model_inputs,\n",
        "      max_new_tokens=512\n",
        "  )\n",
        "\n",
        "  generated_ids = [\n",
        "      output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "  ]\n",
        "\n",
        "  response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "  return response\n",
        "\n",
        "\n",
        "def text_to_prediction(row):\n",
        "    llm_answer = get_llm_date_prediction(row['Date_NER'],row['url'])\n",
        "    row[\"pred\"] = llm_answer\n",
        "    print(row.name, llm_answer)\n",
        "    return row\n"
      ],
      "metadata": {
        "id": "LiTB2WckAVru",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-30T17:08:11.667928Z",
          "iopub.execute_input": "2024-11-30T17:08:11.668326Z",
          "iopub.status.idle": "2024-11-30T17:08:11.675496Z",
          "shell.execute_reply.started": "2024-11-30T17:08:11.668292Z",
          "shell.execute_reply": "2024-11-30T17:08:11.674358Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the prediction (previous 200 rows)\n",
        "new_data_df[\"pred\"] = None\n",
        "new_data_df.loc[:199] = new_data_df.loc[:199].apply(text_to_prediction, axis=1)\n",
        "new_data_df.to_pickle(\"new_data_df_pred_200.pkl\")\n"
      ],
      "metadata": {
        "id": "98HGC2cxhIzn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and our annotation rule\n",
        "The evaluation part features also **our benchmark gold standard** which we annotate consistently with the rules follwing the priority order:\n",
        "\n",
        " 1.  Date prefixed exactly with ‘Mise en ligne le’, “Publié le”,etc\n",
        " 2. Dates declaring the approval or holding of the event: “avis du…”, ‘procès verbal du …’\n",
        " 3.  Date appearing at the end of the document with the signature and prefixed with “fait à XX le…”, \"approuvé le...\",etc\n",
        " 4. If the above rules fail, use the one in the URL\n",
        "\n",
        "\n",
        " We'll then compare the performance of our solution and Datapolitcs on our benchmark and make the analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ta9butj_xKJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "new_data_df = pd.read_pickle(\"/content/new_data_df_pred_200 .pkl\")\n",
        "\n",
        "gold_99 = pd.read_csv(\"/content/gold_annotations_99.csv\") #Our gold annotation\n",
        "\n",
        "pred_datapolitics = pd.read_csv(\"/content/dataset (2).csv\") #Datapolics's original dataset"
      ],
      "metadata": {
        "id": "RhAYCth3xqah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Evaluation on our gold standard\n",
        "\n",
        "# Join the 3 datasets on gold_id\n",
        "merged_df = (\n",
        "    new_data_df[['doc_id', 'pred']]\n",
        "    .rename(columns={'pred': 'pred_new'})\n",
        "    .merge(pred_datapolitics[['doc_id', 'published']].rename(columns={'published': 'pred_datapolitics'}), on='doc_id', how='left')\n",
        "    .merge(gold_99[['doc_id', 'REAL_GOLD']], on='doc_id', how='left')\n",
        ")\n",
        "merged_df = merged_df.dropna(subset=['pred_new', 'pred_datapolitics', 'REAL_GOLD']) # filter out NaN\n",
        "\n",
        "# Calculate results\n",
        "differences_new = merged_df[merged_df['pred_new'] != merged_df['REAL_GOLD']]\n",
        "differences_datapolitics = merged_df[merged_df['pred_datapolitics'] != merged_df['REAL_GOLD']]\n",
        "\n",
        "count_differences_new = len(differences_new)\n",
        "count_differences_datapolitics = len(differences_datapolitics)\n",
        "\n",
        "accuracy_new = (merged_df['pred_new'] == merged_df['REAL_GOLD']).mean()\n",
        "accuracy_datapolitics = (merged_df['pred_datapolitics'] == merged_df['REAL_GOLD']).mean()\n",
        "\n",
        "print(\"Our gold v.s. Our predictions\")\n",
        "print(f\"Number of wrong predictions: {count_differences_new}\")\n",
        "print(f\"Accuracy: {accuracy_new:.2%}\")\n",
        "print('')\n",
        "print(\"Our gold v.s. DataPolitics\")\n",
        "print(f\"Number of wrong predictions: {count_differences_datapolitics}\")\n",
        "print(f\"Accuracy: {accuracy_datapolitics:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMSQ3F6hCcXG",
        "outputId": "b8d2d16f-a5ca-4cf2-a82c-3eb1247fa0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our gold v.s. Our predictions\n",
            "Number of wrong predictions: 23\n",
            "Accuracy: 76.77%\n",
            "\n",
            "Our gold v.s. DataPolitics\n",
            "Number of wrong predictions: 34\n",
            "Accuracy: 65.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our solution performs outperforms the baseline in:**\n",
        "\n",
        "- Taking into account the publication date appearing at the end of the document\n",
        "\n",
        "- Thanks to better OCR, we include more irregular-font date information missing in the texts provided by the baseline solution\n",
        "\n",
        "**Analysis for the still-existing problems and possible solutions:**\n",
        "\n",
        "- Hand-writing dates too difficult for OCR.➡️ If we have enough budget, we could try Google Vision API\n",
        "\n",
        "- The LLM's 'reasoning' doesn't align with our human standards ➡️ Try more advanced prompting(e.g. a more clear stated rule) or even FT strategies(e.g. prefix-tuning)\n",
        "\n",
        "- Some urls are no longer requestable (approximate ratio of 4 out of 200)\n",
        "\n",
        "- The publication date falls outside the scope of our targeted pages (rare)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We also run the evalution using the class's collaborative annotation. Despite our performance still higher than the baseline, we consider it less relevant as this collabrative annotation rule is not clear and consistent, with principles different from ours.👇\n"
      ],
      "metadata": {
        "id": "qo53a7zUadRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Evaluation on the class's annotations\n",
        "!pip install datasets\n",
        "from datasets import load_dataset,Dataset\n",
        "ds = load_dataset(\"maribr/publication_dates_fr\")"
      ],
      "metadata": {
        "id": "Dwpq_KTBNyMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_df = ds['train'].to_pandas()\n",
        "\n",
        "# Join the 3 dataframes on url\n",
        "merged_df = (\n",
        "    new_data_df[['url', 'pred']]\n",
        "    .rename(columns={'pred': 'pred_new'})\n",
        "    .merge(pred_datapolitics[['url', 'published']].rename(columns={'published': 'pred_datapolitics'}), on='url')\n",
        "    .merge(huggingface_df[['url', 'Gold published date']], on='url', how='left')\n",
        ")\n",
        "merged_df = merged_df.dropna(subset=['pred_new', 'pred_datapolitics', 'Gold published date']) # filter out NaN\n",
        "\n",
        "# Calculate results\n",
        "differences_new = merged_df[merged_df['pred_new'] != merged_df['Gold published date']]\n",
        "differences_datapolitics = merged_df[merged_df['pred_datapolitics'] != merged_df['Gold published date']]\n",
        "\n",
        "count_differences_new = len(differences_new)\n",
        "count_differences_datapolitics = len(differences_datapolitics)\n",
        "\n",
        "accuracy_new = (merged_df['pred_new'] == merged_df['Gold published date']).mean()\n",
        "accuracy_datapolitics = (merged_df['pred_datapolitics'] == merged_df['Gold published date']).mean()\n",
        "\n",
        "print(\"The class annotations v.s. Our predictions\")\n",
        "print(f\"Number of wrong predictions: {count_differences_new}\")\n",
        "print(f\"Accuracy: {accuracy_new:.2%}\")\n",
        "print('')\n",
        "print(\"The class annotations v.s. DataPolitics\")\n",
        "print(f\"Number of wrong predictions: {count_differences_datapolitics}\")\n",
        "print(f\"Accuracy: {accuracy_datapolitics:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJbFhHLy_FIm",
        "outputId": "49231936-c04d-43c8-bc6d-1aef85903d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The class annotations v.s. Our predictions\n",
            "Number of wrong predictions: 55\n",
            "Accuracy: 72.36%\n",
            "\n",
            "The class annotations v.s. DataPolitics\n",
            "Number of wrong predictions: 65\n",
            "Accuracy: 67.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df.loc[62]['Date_NER']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOEAXXWGjtcl",
        "outputId": "4f5c0bf7-647b-4599-f84e-3beffab081a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Proces-verbal de la session du',\n",
              " 'Conseil Communautaire du 6 février 2023',\n",
              " 'présidence de Monsieur Jean-Louis CAMUS, Président.',\n",
              " 'Date de convocation : 27 janvier 2023',\n",
              " 'Le quorum étant atteint, le Président ouvre la séance',\n",
              " ' Approbation du proces-verbal de la séance du Conseil Communautaire du 13 décembre 2022',\n",
              " ' Approbation du proces-verbal de la séance du Conseil Communautaire du 13 décembre 2022',\n",
              " 'Le Président donne lecture du procés-verbal de la session du conseil communautaire en date du 13 décembre 2022.',\n",
              " \"Monsieur le Président rappelle l'ordre du jour :\",\n",
              " ' Approbation du PV de séance du conseil communautaire du 13 décembre 2022',\n",
              " 'Décisions du Président',\n",
              " \" Débat d'orientations budgétaires 2023\",\n",
              " 'Affaires économiques.:Boulangerie de MARTIZAY : Assujettissement a la TVA',\n",
              " 'Voirie : Programme de voirie 2023 - lancement des consultations',\n",
              " 'Virement de crédits',\n",
              " 'ARVC 2022 - 02',\n",
              " 'En application des articles L 2322-1 et L2322-2 du Code général des collectivités territoriales et de la circulaire',\n",
              " \"NOR/INT/B/89/00017C du 11 janvier 1989, le président, considérant qu'il est nécessaire d'ouvrir des crédits budgé-\",\n",
              " \"NOR/INT/B/89/00017C du 11 janvier 1989, le président, considérant qu'il est nécessaire d'ouvrir des crédits budgé-\",\n",
              " \"taires pour faire face a des dépenses qui n'ont pas été prévues au budget < Principal > 2021, a demandé au comptable\",\n",
              " '+ 1 179 €',\n",
              " \"D2023-01- Réhabilitation d'un batiment pour y accueillir le CPIE : mission SPS et Controle technique\",\n",
              " \"En application de I'article L. 2122-22 du Code général des collectivités territoriales, et de la délibération du Conseil\",\n",
              " 'Communautaire en date du 30 juillet 2020 accordant délégation au Président, de prendre toute décision concernant la',\n",
              " 'Mission de Contrle technique: SOCOTEC pour un montant de 5 450 £ HT',\n",
              " \"Débat d'orientations budgétaires 2023\",\n",
              " \"Débat d'orientations budgétaires 2023\",\n",
              " \"N° 01/01-2023 - Débat d'orientations budgétaires 2023\",\n",
              " 'Monsieur le Président fait part des orientations budgétaires retenues par le Bureau suite au travail des commissions,',\n",
              " \"pour l'année 2023.\",\n",
              " 'petites retraites.',\n",
              " \"Le Conseil Communautaire, prend acte du débat d'orientations budgétaires 2023.\",\n",
              " ' Personnel',\n",
              " \"01/02-2023- Création de poste d'Adjoint Technique Territorial au service Ecoles - Animation\",\n",
              " \"Monsieur le Président informe le conseil communautaire que suite a la longue maladie d'un agent ATSEM, il est néces-\",\n",
              " 'saire de recruter un Adjoint Technique Territorial ä temps complet au 1er mars 2023. Aussi, il propose de créer un poste',\n",
              " 'saire de recruter un Adjoint Technique Territorial ä temps complet au 1er mars 2023. Aussi, il propose de créer un poste',\n",
              " \"d'Adjoint Technique Territorial a temps complet ä compter du 1er mars 2023.\",\n",
              " \"Le Conseil Communautaire aprés en avoir délibéré, ä I'unanimité, approuve la proposition du Président\",\n",
              " \"01/03-2023 - Modification du temps de travail d'un poste d'Animateur France Services\",\n",
              " \"01/03-2023 - Modification du temps de travail d'un poste d'Animateur France Services\",\n",
              " \"Monsieur le Président rappelle la délibération 03/03-2022 du 10 mai 2022 concernant le recrutement d'un animateur\",\n",
              " \"Monsieur le Président rappelle la délibération 03/03-2022 du 10 mai 2022 concernant le recrutement d'un animateur\",\n",
              " 'France Services a raison de 24h hebdomadaires.',\n",
              " ' Il informe le conseil communautaire que la France services subit une forte affluence des utilisateurs. Il convient de mo-',\n",
              " \"difier le temps de travail de l'animatrice France Services de 24h a 28h hebdomadaires ä compter du 1er mars 2023. Aus-\",\n",
              " ' Il informe le conseil communautaire que la France services subit une forte affluence des utilisateurs. Il convient de mo-',\n",
              " \"difier le temps de travail de l'animatrice France Services de 24h a 28h hebdomadaires ä compter du 1er mars 2023. Aus-\",\n",
              " \"difier le temps de travail de l'animatrice France Services de 24h a 28h hebdomadaires ä compter du 1er mars 2023. Aus-\",\n",
              " \"si, il propose de modifier le temps de travail de I'animatrice France Services ä raison de 28h par semaine ä compter du\",\n",
              " \"si, il propose de modifier le temps de travail de I'animatrice France Services ä raison de 28h par semaine ä compter du\",\n",
              " \"1er mars 2023. Le Conseil Communautaire aprés en avoir délibéré, & l'unanimité, approuve la proposition du Président.\",\n",
              " 'Opération de réhabilitation du groupe scolaire de Méziéres en Brenne',\n",
              " 'N° 01/04-2023 -Réhabilitation du groupe scolaire de Méziéres en Brenne - avenants au marché de travaux',\n",
              " \"Création d'une piste cyclable et piétonne\",\n",
              " \"N° 01/05-2023 - Création d'une piste cyclable et piétonne - avenant au marché de travaux\",\n",
              " ' Ordures ménageres',\n",
              " 'N° 01/09-2023 - Approbation des conventions avec ECOLOGIC pour la reprise des articles de bricolage et de',\n",
              " 'N° 01/10-2023 - Entente intercommunale : Avenant N° 3 a la convention',\n",
              " 'Par délibération en date du 14 décembre 2019, le SYTOM de la région de Chateauroux a approuvé la convention',\n",
              " 'TOM de Chénérailles (23) et le SICTOM de la Champagne Berrichonne.',\n",
              " 'Par délibération en date du 19 septembre 2022, la communauté de communes de la Marche Berrichonne a pris la déci-',\n",
              " ' < classiques >, le coüt total supplémentaire est de 6,42£, soit un coút unitaire par caractérisation de 93,22€ ä compter du',\n",
              " '1er janvier 2023.',\n",
              " 'Consultation du conseil communautaire',\n",
              " 'N° 01/11-2023 - Proiet Eolien de BUZANCAIS : consultation du Conseil Communautaire pour avis',\n",
              " 'Monsieur le Président informe le conseil des prochaines dates ä retenir :',\n",
              " ' Bureau, le 7 mars 2023',\n",
              " ' Bureau, le 7 mars 2023',\n",
              " '- Conseil Communautaire avec notamment le vote du budget, le 13 mars 2023',\n",
              " '- Conseil Communautaire avec notamment le vote du budget, le 13 mars 2023',\n",
              " \"L'ordre du jour étant épuisé, le Président léve la séance ä 20h.\",\n",
              " 'Jean-Louis $AMUS',\n",
              " 'Arrété lors de la session du : .3 7aus 223',\n",
              " 'Jean-Louis $AMUS',\n",
              " 'Arrété lors de la session du : .3 7aus 223']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "differences_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "9biZV24Ai-D1",
        "outputId": "63cb4eff-b331-4148-b673-9e49ecdf8004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               doc_id    pred_new  \\\n",
              "4                         3132/6df22_cms_viewFile.php  23/01/2023   \n",
              "10                        3132/b91a1_cms_viewFile.php  13/02/2023   \n",
              "15                                   679/864c8_ca.pdf  14/02/2023   \n",
              "20                            1058/fb940_2023.020.pdf  17/02/2023   \n",
              "23                    1220/55539_pv30012023-signe.pdf  30/01/2023   \n",
              "24              693/f5db7_RAPPORT_BP_2023_COMMUNE.pdf  31/01/2023   \n",
              "27  3031/415be_TOME-3_Plan-dactions-Suivi-Evaluati...  01/01/2023   \n",
              "30                2432/1775c_Couvron-2-Règlement.pdf  27/01/2023   \n",
              "36  2120/6aa7b_8979238261_1352_pv-conseil-19-janvi...  19/01/2023   \n",
              "37    6608/8e06f_Deliberations-du-23-janvier-2023.pdf  17/01/2023   \n",
              "44  713/46f28_Comptes-Administratifs-2022-Mairie-d...  31/12/2022   \n",
              "49  2965/18c3595af8e450d0b8afffe9827a617fcfa8450f_...  30/04/2023   \n",
              "51  1970/5011763f908fe9bdec498bdf9cb1517bb66fbb56_...  30/03/2023   \n",
              "53  4039/1cc9a1365b42da090209998401bdc104826d7537_...  30/03/2017   \n",
              "54  3395/bfdd09c728391ba9f29bf516a68553dedcd243cd_...  29/03/2023   \n",
              "57                             3176/6300b_TOME_II.pdf  23/02/2023   \n",
              "62  2983/5edce_PV-conseil-communautaire-6_-02-2023...  06/02/2023   \n",
              "70  3029/a18582e994fceea2089730c835eba47315a1cc6d_...  06/02/2023   \n",
              "71  204/0c1492b7c0d5578a8936bae374fb04c334a2be17_P...  09/02/2023   \n",
              "73        1930/d6f5f_PC-94078-2200041-1-MARS-2023.pdf  01/03/2023   \n",
              "78  2675/4382452d089293027ea731276a13a0d1bead769f_...  10/03/2023   \n",
              "81  1924/139073868fce0a69a041db8cabee920b82f209ed_...  27/04/2023   \n",
              "95  295/d6cc0b38662d547297633c711e2b8db289ecafdd_p...  13/12/2022   \n",
              "\n",
              "   pred_datapolitics   REAL_GOLD  \n",
              "4         16/01/2023  16/01/2023  \n",
              "10        13/02/2023  06/03/2023  \n",
              "15        17/02/2023  17/02/2023  \n",
              "20        17/02/2023  24/02/2023  \n",
              "23        30/01/2023  27/02/2023  \n",
              "24        01/01/2023  01/01/2023  \n",
              "27        12/01/2023  12/01/2023  \n",
              "30        01/01/2023  01/01/2023  \n",
              "36        19/01/2023  20/02/2023  \n",
              "37        23/01/2023  23/01/2023  \n",
              "44        01/03/2023  01/03/2023  \n",
              "49        29/03/2023  29/03/2023  \n",
              "51        30/03/2023  07/04/2023  \n",
              "53        01/03/2023  15/03/2017  \n",
              "54        09/03/2023  30/03/2023  \n",
              "57        23/02/2023  28/02/2023  \n",
              "62        06/02/2023  02/03/2023  \n",
              "70        06/02/2023  09/02/2023  \n",
              "71        09/02/2023  10/02/2023  \n",
              "73        02/03/2023  02/03/2023  \n",
              "78        20/03/2023  29/06/2023  \n",
              "81        31/03/2023  12/04/2023  \n",
              "95        23/03/2023  11/04/2023  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f4b40d5-b12e-40ee-b59d-fd4930741731\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>pred_new</th>\n",
              "      <th>pred_datapolitics</th>\n",
              "      <th>REAL_GOLD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3132/6df22_cms_viewFile.php</td>\n",
              "      <td>23/01/2023</td>\n",
              "      <td>16/01/2023</td>\n",
              "      <td>16/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3132/b91a1_cms_viewFile.php</td>\n",
              "      <td>13/02/2023</td>\n",
              "      <td>13/02/2023</td>\n",
              "      <td>06/03/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>679/864c8_ca.pdf</td>\n",
              "      <td>14/02/2023</td>\n",
              "      <td>17/02/2023</td>\n",
              "      <td>17/02/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1058/fb940_2023.020.pdf</td>\n",
              "      <td>17/02/2023</td>\n",
              "      <td>17/02/2023</td>\n",
              "      <td>24/02/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1220/55539_pv30012023-signe.pdf</td>\n",
              "      <td>30/01/2023</td>\n",
              "      <td>30/01/2023</td>\n",
              "      <td>27/02/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>693/f5db7_RAPPORT_BP_2023_COMMUNE.pdf</td>\n",
              "      <td>31/01/2023</td>\n",
              "      <td>01/01/2023</td>\n",
              "      <td>01/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3031/415be_TOME-3_Plan-dactions-Suivi-Evaluati...</td>\n",
              "      <td>01/01/2023</td>\n",
              "      <td>12/01/2023</td>\n",
              "      <td>12/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2432/1775c_Couvron-2-Règlement.pdf</td>\n",
              "      <td>27/01/2023</td>\n",
              "      <td>01/01/2023</td>\n",
              "      <td>01/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2120/6aa7b_8979238261_1352_pv-conseil-19-janvi...</td>\n",
              "      <td>19/01/2023</td>\n",
              "      <td>19/01/2023</td>\n",
              "      <td>20/02/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>6608/8e06f_Deliberations-du-23-janvier-2023.pdf</td>\n",
              "      <td>17/01/2023</td>\n",
              "      <td>23/01/2023</td>\n",
              "      <td>23/01/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>713/46f28_Comptes-Administratifs-2022-Mairie-d...</td>\n",
              "      <td>31/12/2022</td>\n",
              "      <td>01/03/2023</td>\n",
              "      <td>01/03/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2965/18c3595af8e450d0b8afffe9827a617fcfa8450f_...</td>\n",
              "      <td>30/04/2023</td>\n",
              "      <td>29/03/2023</td>\n",
              "      <td>29/03/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>1970/5011763f908fe9bdec498bdf9cb1517bb66fbb56_...</td>\n",
              "      <td>30/03/2023</td>\n",
              "      <td>30/03/2023</td>\n",
              "      <td>07/04/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>4039/1cc9a1365b42da090209998401bdc104826d7537_...</td>\n",
              "      <td>30/03/2017</td>\n",
              "      <td>01/03/2023</td>\n",
              "      <td>15/03/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>3395/bfdd09c728391ba9f29bf516a68553dedcd243cd_...</td>\n",
              "      <td>29/03/2023</td>\n",
              "      <td>09/03/2023</td>\n",
              "      <td>30/03/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>3176/6300b_TOME_II.pdf</td>\n",
              "      <td>23/02/2023</td>\n",
              "      <td>23/02/2023</td>\n",
              "      <td>28/02/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>2983/5edce_PV-conseil-communautaire-6_-02-2023...</td>\n",
              "      <td>06/02/2023</td>\n",
              "      <td>06/02/2023</td>\n",
              "      <td>02/03/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>3029/a18582e994fceea2089730c835eba47315a1cc6d_...</td>\n",
              "      <td>06/02/2023</td>\n",
              "      <td>06/02/2023</td>\n",
              "      <td>09/02/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>204/0c1492b7c0d5578a8936bae374fb04c334a2be17_P...</td>\n",
              "      <td>09/02/2023</td>\n",
              "      <td>09/02/2023</td>\n",
              "      <td>10/02/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1930/d6f5f_PC-94078-2200041-1-MARS-2023.pdf</td>\n",
              "      <td>01/03/2023</td>\n",
              "      <td>02/03/2023</td>\n",
              "      <td>02/03/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>2675/4382452d089293027ea731276a13a0d1bead769f_...</td>\n",
              "      <td>10/03/2023</td>\n",
              "      <td>20/03/2023</td>\n",
              "      <td>29/06/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>1924/139073868fce0a69a041db8cabee920b82f209ed_...</td>\n",
              "      <td>27/04/2023</td>\n",
              "      <td>31/03/2023</td>\n",
              "      <td>12/04/2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>295/d6cc0b38662d547297633c711e2b8db289ecafdd_p...</td>\n",
              "      <td>13/12/2022</td>\n",
              "      <td>23/03/2023</td>\n",
              "      <td>11/04/2023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f4b40d5-b12e-40ee-b59d-fd4930741731')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f4b40d5-b12e-40ee-b59d-fd4930741731 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f4b40d5-b12e-40ee-b59d-fd4930741731');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ce51fb3-16f2-4e48-8a62-eb917ed9fdc4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ce51fb3-16f2-4e48-8a62-eb917ed9fdc4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ce51fb3-16f2-4e48-8a62-eb917ed9fdc4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_397e371c-1843-4b0c-ade8-6832e8d19551\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('differences_new')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_397e371c-1843-4b0c-ade8-6832e8d19551 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('differences_new');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "differences_new",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}